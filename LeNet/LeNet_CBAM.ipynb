{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPCvNqIgIqoRbl8TM4b2nlC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["LeNet with and without CBAM"],"metadata":{"id":"tK9BPd1GOn38"}},{"cell_type":"code","source":["pip install torchmetrics\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFf3vXfMlcub","executionInfo":{"status":"ok","timestamp":1733520514372,"user_tz":-300,"elapsed":5289,"user":{"displayName":"k238073 Anas Zahid","userId":"04237435265070369924"}},"outputId":"1ebeba7a-01ba-4544-b17a-e98f760e090e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n","Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Define the CBAM (Convolutional Block Attention Module)\n","class CBAM(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super(CBAM, self).__init__()\n","        self.channel_attention = ChannelAttention(channels, reduction)\n","        self.spatial_attention = SpatialAttention()\n","\n","    def forward(self, x):\n","        x = self.channel_attention(x)\n","        x = self.spatial_attention(x)\n","        return x\n","\n","class ChannelAttention(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super(ChannelAttention, self).__init__()\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_pool = F.adaptive_avg_pool2d(x, 1)\n","        max_pool = F.adaptive_max_pool2d(x, 1)\n","        avg_out = self.fc2(F.relu(self.fc1(avg_pool)))\n","        max_out = self.fc2(F.relu(self.fc1(max_pool)))\n","        out = avg_out + max_out\n","        return x * self.sigmoid(out)\n","\n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_pool = torch.mean(x, dim=1, keepdim=True)\n","        max_pool, _ = torch.max(x, dim=1, keepdim=True)\n","        x_cat = torch.cat([avg_pool, max_pool], dim=1)\n","        return x * self.sigmoid(self.conv(x_cat))\n","\n","# LeNet model with and without CBAM\n","class LeNet(nn.Module):\n","    def __init__(self, use_cbam=False):\n","        super(LeNet, self).__init__()\n","        self.use_cbam = use_cbam\n","\n","        # LeNet layers\n","        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)\n","        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n","        self.conv3 = nn.Conv2d(16, 120, kernel_size=5)\n","        self.fc1 = nn.Linear(120 * 2 * 2, 84)  # Corrected input size for flattened tensor\n","        self.fc2 = nn.Linear(84, 100)  # CIFAR-100 has 100 classes\n","\n","        # CBAM module (applied after final convolution layer)\n","        if self.use_cbam:\n","            self.cbam = CBAM(120)\n","        else:\n","            self.cbam = None\n","\n","    def forward(self, x):\n","        # Apply first convolutional layer\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        print(f\"After conv1: {x.shape}\")  # Debugging print statement\n","\n","        # Apply second convolutional layer\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        print(f\"After conv2: {x.shape}\")  # Debugging print statement\n","\n","        # Apply third convolutional layer\n","        x = F.relu(self.conv3(x))\n","        print(f\"After conv3: {x.shape}\")  # Debugging print statement\n","\n","        # Apply CBAM after the final convolution if enabled\n","        if self.cbam:\n","            x = self.cbam(x)\n","        print(f\"After CBAM (if applied): {x.shape}\")  # Debugging print statement\n","\n","        # Flatten the tensor before passing it to the fully connected layers\n","        x = x.view(x.size(0), -1)  # Flatten the tensor dynamically\n","        print(f\"After flatten: {x.shape}\")  # Debugging print statement\n","\n","        # Pass through the fully connected layers\n","        x = F.relu(self.fc1(x))\n","        print(f\"After fc1: {x.shape}\")  # Debugging print statement\n","        x = self.fc2(x)\n","        print(f\"After fc2: {x.shape}\")  # Debugging print statement\n","        return x\n","\n","# Load CIFAR-100 dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n","testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n","\n","trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n","testloader = DataLoader(testset, batch_size=100, shuffle=False)\n","\n","# Training function\n","def train(model, trainloader, criterion, optimizer, device, num_epochs=20):\n","    best_acc = 0\n","    model.to(device)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        for inputs, labels in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Calculate training accuracy\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        train_acc = 100 * correct / total\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Training Accuracy: {train_acc:.2f}%\")\n","\n","        # Update best accuracy\n","        if train_acc > best_acc:\n","            best_acc = train_acc\n","        print(f\"Best Accuracy so far: {best_acc:.2f}%\")\n","\n","    print(\"Finished Training\")\n","\n","# Testing function for top-1 and top-5 accuracy\n","def test(model, testloader, device):\n","    model.eval()\n","    top1 = 0\n","    top5 = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in tqdm(testloader, desc=\"Testing\"):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.topk(outputs, 5, dim=1)\n","            correct1 = (preds[:, 0] == labels).sum().item()\n","            correct5 = (preds == labels.view(-1, 1).expand_as(preds)).sum().item()\n","            total += labels.size(0)\n","            top1 += correct1\n","            top5 += correct5\n","\n","    top1_accuracy = 100 * top1 / total\n","    top5_accuracy = 100 * top5 / total\n","    print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n","    print(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")\n","\n","# Initialize models, loss function, and optimizers\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# LeNet with CBAM\n","model_with_cbam = LeNet(use_cbam=True)\n","optimizer_with_cbam = optim.Adam(model_with_cbam.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","# LeNet without CBAM\n","model_without_cbam = LeNet(use_cbam=False)\n","optimizer_without_cbam = optim.Adam(model_without_cbam.parameters(), lr=0.001)\n","\n","# Train LeNet with CBAM\n","print(\"Training LeNet with CBAM...\")\n","train(model_with_cbam, trainloader, criterion, optimizer_with_cbam, device, num_epochs=20)\n","\n","# Train LeNet without CBAM\n","print(\"Training LeNet without CBAM...\")\n","train(model_without_cbam, trainloader, criterion, optimizer_without_cbam, device, num_epochs=20)\n","\n","# Test both models\n","print(\"\\nEvaluating LeNet with CBAM:\")\n","test(model_with_cbam, testloader, device)\n","\n","print(\"\\nEvaluating LeNet without CBAM:\")\n","test(model_without_cbam, testloader, device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1op17sOAuG4YQoIpDYd0hl2k80UrcSSn0"},"id":"DoZYsQytshQb","outputId":"d0908802-21de-4ad8-9c21-341f88b4c619","executionInfo":{"status":"ok","timestamp":1733521514697,"user_tz":-300,"elapsed":101851,"user":{"displayName":"k238073 Anas Zahid","userId":"04237435265070369924"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}