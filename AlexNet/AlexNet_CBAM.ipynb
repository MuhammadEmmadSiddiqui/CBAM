{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbY1mthTXp8Y",
        "outputId": "b3190e1b-b8a7-4720-b477-cd83281678be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install torchmetrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCtdE-KYW_Cp",
        "outputId": "18ef5366-2db4-431d-c6bc-fbdbd01491a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training AlexNet without CBAM\n",
            "Epoch [1/20]\n",
            "Loss: 4.1851\n",
            "Current Top-1 Accuracy: 0.0012\n",
            "Best Top-1 Accuracy: 0.0012\n",
            "Epoch Top-1 Accuracy: 0.0008\n",
            "Epoch [2/20]\n",
            "Loss: 3.6408\n",
            "Current Top-1 Accuracy: 0.0018\n",
            "Best Top-1 Accuracy: 0.0018\n",
            "Epoch Top-1 Accuracy: 0.0021\n",
            "Epoch [3/20]\n",
            "Loss: 3.3788\n",
            "Current Top-1 Accuracy: 0.0022\n",
            "Best Top-1 Accuracy: 0.0022\n",
            "Epoch Top-1 Accuracy: 0.0029\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchmetrics.classification import Accuracy\n",
        "\n",
        "# CBAM Implementation\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1, bias=False)\n",
        "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1, bias=False)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu(self.fc1(torch.mean(x, dim=(2, 3), keepdim=True))))\n",
        "        max_out = self.fc2(self.relu(self.fc1(torch.amax(x, dim=(2, 3), keepdim=True))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out) * x\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        out = torch.cat([avg_out, max_out], dim=1)\n",
        "        out = self.conv(out)\n",
        "        return self.sigmoid(out) * x\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16, kernel_size=7):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_attention = ChannelAttention(in_channels, reduction)\n",
        "        self.spatial_attention = SpatialAttention(kernel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_attention(x)\n",
        "        x = self.spatial_attention(x)\n",
        "        return x\n",
        "\n",
        "# AlexNet without CBAM\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# AlexNet with CBAM\n",
        "class AlexNet_CBAM(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(AlexNet_CBAM, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            CBAM(64),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            CBAM(192),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            CBAM(384),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            CBAM(256),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# CIFAR-100 Dataset Preparation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize for AlexNet\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize models, loss function, and optimizers\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "alexnet = AlexNet(num_classes=100).to(device)\n",
        "alexnet_cbam = AlexNet_CBAM(num_classes=100).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_alexnet = optim.Adam(alexnet.parameters(), lr=0.001)\n",
        "optimizer_alexnet_cbam = optim.Adam(alexnet_cbam.parameters(), lr=0.001)\n",
        "\n",
        "# Top-1 Accuracy\n",
        "top1_acc = Accuracy(task=\"multiclass\", num_classes=100, top_k=1).to(device)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate(model, testloader):\n",
        "    model.eval()\n",
        "    top1 = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            top1 += top1_acc(outputs, labels)\n",
        "            total += labels.size(0)\n",
        "    return top1 / total\n",
        "\n",
        "# Training Function with Current and Best Accuracy for Each Epoch\n",
        "def train_model(model, trainloader, testloader, optimizer, num_epochs=20):\n",
        "    best_top1_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        epoch_top1_acc = 0.0\n",
        "        total = 0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy for each batch\n",
        "            batch_top1 = top1_acc(outputs, labels)\n",
        "\n",
        "            epoch_top1_acc += batch_top1\n",
        "            total += labels.size(0)\n",
        "\n",
        "        # Average accuracy for the epoch\n",
        "        epoch_top1_acc /= total\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        current_top1_acc = evaluate(model, testloader)\n",
        "\n",
        "        # Update best accuracy\n",
        "        if current_top1_acc > best_top1_acc:\n",
        "            best_top1_acc = current_top1_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"Loss: {running_loss/len(trainloader):.4f}\")\n",
        "        print(f\"Current Top-1 Accuracy: {current_top1_acc:.4f}\")\n",
        "        print(f\"Best Top-1 Accuracy: {best_top1_acc:.4f}\")\n",
        "        print(f\"Epoch Top-1 Accuracy: {epoch_top1_acc:.4f}\")\n",
        "\n",
        "# Choose model and optimizer for training\n",
        "print(\"Training AlexNet without CBAM\")\n",
        "train_model(alexnet, trainloader, testloader, optimizer_alexnet, num_epochs=20)\n",
        "\n",
        "print(\"Training AlexNet with CBAM\")\n",
        "train_model(alexnet_cbam, trainloader, testloader, optimizer_alexnet_cbam, num_epochs=20)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}