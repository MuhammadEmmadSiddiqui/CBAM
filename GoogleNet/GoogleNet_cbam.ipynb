{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0fwj2xBjE4E6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torchvision.datasets as dataset\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-uNaCfZPgTUu"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvfWrKZwE4E8"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AegtXewuc4nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a9ed18-414d-4907-d634-9b118787ea2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./CIFAR100/train/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:06<00:00, 24.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CIFAR100/train/cifar-100-python.tar.gz to ./CIFAR100/train\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dataset.CIFAR100(root=\"./CIFAR100/train\", train=True, transform=None, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_guRntscPM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618c49c3-9e0e-4ea4-cc80-64d69114adf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: [0.5070751592371323, 0.48654887331495095, 0.4409178433670343]\n",
            "std: [0.26733428587941854, 0.25643846292120615, 0.2761504713263903]\n"
          ]
        }
      ],
      "source": [
        "x = np.concatenate([np.asarray(train_dataset[i][0]) for i in range(len(train_dataset))])\n",
        "mean = np.mean(x, axis=(0, 1))/255\n",
        "std = np.std(x, axis=(0,1))/255\n",
        "\n",
        "mean = mean.tolist()\n",
        "std = std.tolist()\n",
        "\n",
        "print(\"mean:\", mean)\n",
        "print(\"std:\", std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jnivY6thE4E9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f14d605-28b9-449a-862c-9703cdcf8906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./CIFAR100/val/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:09<00:00, 17.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CIFAR100/val/cifar-100-python.tar.gz to ./CIFAR100/val\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./CIFAR100/test/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:06<00:00, 24.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CIFAR100/test/cifar-100-python.tar.gz to ./CIFAR100/test\n"
          ]
        }
      ],
      "source": [
        "transform = T.Compose([T.ToTensor(),\n",
        "                       T.Normalize(mean, std, inplace=True)])\n",
        "train_dataset = dataset.CIFAR100(root=\"./CIFAR100/train\", train=True, transform=transform, download=True)\n",
        "valid_dataset = dataset.CIFAR100(root=\"./CIFAR100/val\", train=True, transform=transform, download=True)\n",
        "test_dataset = dataset.CIFAR100(root=\"./CIFAR100/test\", train=False, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-vArjQBOE4E-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9397870c-f86c-462a-da29-3006eed5c464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=256, shuffle=False, num_workers=8)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZIPfRoU6E4E-"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3nxHFxqmE4E-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65aaa447-8d43-48bd-87b1-f023a202e00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3, 32, 32])\n",
            "torch.Size([256])\n",
            "tensor([27, 10, 73, 51, 53, 82, 21, 44, 47,  5, 94, 57, 17, 94, 92, 91, 53, 76,\n",
            "        45, 46, 52, 30, 30, 85, 39, 70,  2,  6, 30, 58, 36, 67, 61, 38, 28, 10,\n",
            "        61, 46, 43, 61, 27, 22, 86, 11, 43, 87, 78, 47, 97,  2, 94, 16, 79, 92,\n",
            "        84,  8, 91, 35, 61, 55, 75, 42, 60, 49, 41, 96, 46, 97, 37, 34, 58,  4,\n",
            "        89, 51, 92, 62, 66, 40, 95, 26, 31, 86, 33, 82, 58, 14, 68, 26, 96, 23,\n",
            "        87, 82, 15, 65, 26,  3,  1, 92, 60, 32, 16, 44, 20, 86, 36, 56, 99, 61,\n",
            "        72, 46, 91, 84, 89, 30, 37,  0, 69, 68, 58, 11, 46, 41, 98, 46, 15,  2,\n",
            "        21, 37, 59, 79, 88, 71, 65, 70, 60, 21, 62, 92, 40, 29,  6, 48, 40, 66,\n",
            "        90, 98, 44, 64, 46, 13,  6,  6, 18, 80, 33, 76, 27, 45, 11, 61, 59, 96,\n",
            "        60, 25, 80, 66, 48, 87, 24,  1, 35, 56,  2, 30,  3,  7, 29, 47, 81, 23,\n",
            "         2, 91, 12,  3, 40, 15, 70, 68, 25,  3, 31, 73, 10, 87, 85, 45, 74, 58,\n",
            "         7, 56, 20, 84, 93, 34, 15, 45,  4, 82, 61, 42, 10, 82, 91, 46, 58, 99,\n",
            "        74,  6, 43, 99, 21, 23, 37, 89, 35, 17, 32, 16, 88, 21, 14, 38, 28, 27,\n",
            "        79, 91, 90, 99, 23, 15, 35, 98, 65, 12, 61, 21, 56, 20, 80, 28, 35, 41,\n",
            "        31, 87,  7, 68])\n"
          ]
        }
      ],
      "source": [
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WYBpunpE4E_"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7pCCEZNzE4E_"
      },
      "outputs": [],
      "source": [
        "# No CBAM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        # 1x1 convolution branch\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch1x1, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(ch1x1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3x3 convolution branch\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(ch3x3red),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(ch3x3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 5x5 convolution branch\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(ch5x5red),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(ch5x5),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Max pooling branch\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(pool_proj),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([\n",
        "            self.branch1(x),\n",
        "            self.branch2(x),\n",
        "            self.branch3(x),\n",
        "            self.branch4(x)\n",
        "        ], 1)\n",
        "\n",
        "class AuxiliaryClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(AuxiliaryClassifier, self).__init__()\n",
        "        self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 128, kernel_size=1, stride=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.averagePool(x)\n",
        "        x = self.conv(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class GoogleNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=1000):\n",
        "        super(GoogleNet, self).__init__()\n",
        "\n",
        "        # Initial convolution layers\n",
        "        self.prelayers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        )\n",
        "\n",
        "        # Inception modules\n",
        "        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
        "\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        # Auxiliary Classifiers\n",
        "        self.aux1 = AuxiliaryClassifier(512, num_classes)\n",
        "        self.aux2 = AuxiliaryClassifier(528, num_classes)\n",
        "\n",
        "        # Final layers\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial layers\n",
        "        x = self.prelayers(x)\n",
        "\n",
        "        # Inception modules\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        aux1 = self.aux1(x) if self.training else None\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        aux2 = self.aux2(x) if self.training else None\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        # Final classification\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x, aux1, aux2 if self.training else x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Tsc4eye3-Qja"
      },
      "outputs": [],
      "source": [
        "# With CBAM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SAM(nn.Module):\n",
        "    def __init__(self, bias=False):\n",
        "        super(SAM, self).__init__()\n",
        "        self.bias = bias\n",
        "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        max_pool = torch.max(x, 1)[0].unsqueeze(1)\n",
        "        avg_pool = torch.mean(x, 1).unsqueeze(1)\n",
        "        concat = torch.cat((max_pool, avg_pool), dim=1)\n",
        "        output = self.conv(concat)\n",
        "        output = output * x\n",
        "        return output\n",
        "\n",
        "class CAM(nn.Module):\n",
        "    def __init__(self, channels, r):\n",
        "        super(CAM, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.r = r\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(in_features=self.channels, out_features=max(self.channels//self.r, 1), bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features=max(self.channels//self.r, 1), out_features=self.channels, bias=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        max_pool = F.adaptive_max_pool2d(x, output_size=1)\n",
        "        avg_pool = F.adaptive_avg_pool2d(x, output_size=1)\n",
        "        b, c, _, _ = x.size()\n",
        "        linear_max = self.linear(max_pool.view(b, c)).view(b, c, 1, 1)\n",
        "        linear_avg = self.linear(avg_pool.view(b, c)).view(b, c, 1, 1)\n",
        "        output = linear_max + linear_avg\n",
        "        output = F.sigmoid(output) * x\n",
        "        return output\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, r):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.r = r\n",
        "        self.sam = SAM(bias=False)\n",
        "        self.cam = CAM(channels=self.channels, r=self.r)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.cam(x)\n",
        "        output = self.sam(output)\n",
        "        return output + x\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj, use_cbam=False, r=4):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        # 1x1 convolution branch\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch1x1, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(ch1x1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3x3 convolution branch\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(ch3x3red),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(ch3x3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 5x5 convolution branch\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(ch5x5red),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(ch5x5),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Max pooling branch\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(pool_proj),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Optional CBAM\n",
        "        self.cbam = CBAM(ch1x1 + ch3x3 + ch5x5 + pool_proj, r) if use_cbam else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = [\n",
        "            self.branch1(x),\n",
        "            self.branch2(x),\n",
        "            self.branch3(x),\n",
        "            self.branch4(x)\n",
        "        ]\n",
        "\n",
        "        x = torch.cat(outputs, 1)\n",
        "\n",
        "        if self.cbam is not None:\n",
        "            x = self.cbam(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class AuxiliaryClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(AuxiliaryClassifier, self).__init__()\n",
        "        self.averagePool = nn.AdaptiveAvgPool2d(output_size=(4, 4))\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 128, kernel_size=1, stride=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.averagePool(x)\n",
        "        x = self.conv(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class GoogleNet_CBAM(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=1000, r=4):\n",
        "        super(GoogleNet_CBAM, self).__init__()\n",
        "\n",
        "        # Initial convolution layers\n",
        "        self.prelayers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        )\n",
        "\n",
        "        # Inception modules with optional CBAM\n",
        "        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32, use_cbam=True, r=r)\n",
        "        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64, use_cbam=True, r=r)\n",
        "\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64, use_cbam=True, r=r)\n",
        "        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64, use_cbam=True, r=r)\n",
        "        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64, use_cbam=True, r=r)\n",
        "        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64, use_cbam=True, r=r)\n",
        "        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128, use_cbam=True, r=r)\n",
        "\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128, use_cbam=True, r=r)\n",
        "        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128, use_cbam=True, r=r)\n",
        "\n",
        "        # Auxiliary Classifiers\n",
        "        self.aux1 = AuxiliaryClassifier(512, num_classes)\n",
        "        self.aux2 = AuxiliaryClassifier(528, num_classes)\n",
        "\n",
        "        # Final layers\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial layers\n",
        "        x = self.prelayers(x)\n",
        "\n",
        "        # Inception modules\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        aux1 = self.aux1(x) if self.training else None\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        aux2 = self.aux2(x) if self.training else None\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        # Final classification\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x, aux1, aux2 if self.training else x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro9IAsRIE4FA"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "triISVhHE4FA"
      },
      "outputs": [],
      "source": [
        "model1 = GoogleNet_CBAM(in_channels=3, num_classes=100)\n",
        "optimizer1 = optim.AdamW(model1.parameters(), lr=0.0001, weight_decay=0.005)\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "total_epochs = 50\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model1 = model1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = GoogleNet(in_channels=3, num_classes=100)\n",
        "optimizer2 = optim.AdamW(model2.parameters(), lr=0.0001, weight_decay=0.005)\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "total_epochs = 50\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model2 = model2.to(device)"
      ],
      "metadata": {
        "id": "ImV9peXkQy7S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g52lyNKxE4FA"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, val_loader, criterion, total_epochs, name):\n",
        "    print(\"Training Begin!\")\n",
        "    print()\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            # Get outputs from the model\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Handle tuple output\n",
        "            if isinstance(outputs, tuple):\n",
        "                main_output, aux1, aux2 = outputs\n",
        "                loss = criterion(main_output, labels)\n",
        "\n",
        "                # Include auxiliary loss (optional)\n",
        "                if aux1 is not None and aux2 is not None:\n",
        "                    loss_aux1 = criterion(aux1, labels)\n",
        "                    loss_aux2 = criterion(aux2, labels)\n",
        "                    loss += 0.3 * (loss_aux1 + loss_aux2)  # Weighted auxiliary losses\n",
        "\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step+1) % 30 == 0:\n",
        "                print('Epoch: [{}/{}] | Step: [{}/{}] | Loss: {:.4f}'.format(epoch+1, total_epochs, step+1, len(train_loader), loss.item()))\n",
        "\n",
        "        # Validation\n",
        "        with torch.no_grad():\n",
        "            print(\"Validating...\")\n",
        "            model.eval()\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            for (images, labels) in val_loader:\n",
        "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "                outputs = model(images)\n",
        "                if isinstance(outputs, tuple):  # Get main output for validation\n",
        "                    outputs = outputs[0]\n",
        "\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            acc = (correct/total)*100\n",
        "            if acc > best_accuracy:\n",
        "                best_accuracy = acc\n",
        "                torch.save(model.state_dict(), f\"./{name}.pt\")\n",
        "            print(f\"Current Accuracy: {acc:.3f}%\")\n",
        "            print(f\"Best Accuracy: {best_accuracy:.3f}%\")\n",
        "            print()\n",
        "\n",
        "    print('Train Finished!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GN-UQH6dE4FA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfcf103-9ea8-4141-9ece-b3421bd62492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Begin!\n",
            "\n",
            "Epoch: [1/50] | Step: [30/196] | Loss: 7.3742\n",
            "Epoch: [1/50] | Step: [60/196] | Loss: 7.2986\n",
            "Epoch: [1/50] | Step: [90/196] | Loss: 6.8892\n",
            "Epoch: [1/50] | Step: [120/196] | Loss: 6.7202\n",
            "Epoch: [1/50] | Step: [150/196] | Loss: 6.3780\n",
            "Epoch: [1/50] | Step: [180/196] | Loss: 6.3991\n",
            "Validating...\n",
            "Current Accuracy: 12.696%\n",
            "Best Accuracy: 12.696%\n",
            "\n",
            "Epoch: [2/50] | Step: [30/196] | Loss: 6.0709\n",
            "Epoch: [2/50] | Step: [60/196] | Loss: 6.0287\n",
            "Epoch: [2/50] | Step: [90/196] | Loss: 5.9205\n",
            "Epoch: [2/50] | Step: [120/196] | Loss: 5.8411\n",
            "Epoch: [2/50] | Step: [150/196] | Loss: 5.6781\n",
            "Epoch: [2/50] | Step: [180/196] | Loss: 5.8708\n",
            "Validating...\n",
            "Current Accuracy: 21.348%\n",
            "Best Accuracy: 21.348%\n",
            "\n",
            "Epoch: [3/50] | Step: [30/196] | Loss: 5.4247\n",
            "Epoch: [3/50] | Step: [60/196] | Loss: 5.2067\n",
            "Epoch: [3/50] | Step: [90/196] | Loss: 5.2624\n",
            "Epoch: [3/50] | Step: [120/196] | Loss: 5.2374\n",
            "Epoch: [3/50] | Step: [150/196] | Loss: 5.1313\n",
            "Epoch: [3/50] | Step: [180/196] | Loss: 5.0951\n",
            "Validating...\n",
            "Current Accuracy: 28.174%\n",
            "Best Accuracy: 28.174%\n",
            "\n",
            "Epoch: [4/50] | Step: [30/196] | Loss: 4.8924\n",
            "Epoch: [4/50] | Step: [60/196] | Loss: 4.5196\n",
            "Epoch: [4/50] | Step: [90/196] | Loss: 4.3655\n",
            "Epoch: [4/50] | Step: [120/196] | Loss: 4.8260\n",
            "Epoch: [4/50] | Step: [150/196] | Loss: 4.6576\n",
            "Epoch: [4/50] | Step: [180/196] | Loss: 4.6517\n",
            "Validating...\n",
            "Current Accuracy: 34.914%\n",
            "Best Accuracy: 34.914%\n",
            "\n",
            "Epoch: [5/50] | Step: [30/196] | Loss: 4.2142\n",
            "Epoch: [5/50] | Step: [60/196] | Loss: 4.1537\n",
            "Epoch: [5/50] | Step: [90/196] | Loss: 4.6807\n",
            "Epoch: [5/50] | Step: [120/196] | Loss: 4.2360\n",
            "Epoch: [5/50] | Step: [150/196] | Loss: 4.2454\n",
            "Epoch: [5/50] | Step: [180/196] | Loss: 4.0458\n",
            "Validating...\n",
            "Current Accuracy: 41.738%\n",
            "Best Accuracy: 41.738%\n",
            "\n",
            "Epoch: [6/50] | Step: [30/196] | Loss: 3.9312\n",
            "Epoch: [6/50] | Step: [60/196] | Loss: 4.0401\n",
            "Epoch: [6/50] | Step: [90/196] | Loss: 3.6012\n",
            "Epoch: [6/50] | Step: [120/196] | Loss: 3.8610\n",
            "Epoch: [6/50] | Step: [150/196] | Loss: 4.1833\n",
            "Epoch: [6/50] | Step: [180/196] | Loss: 4.3054\n",
            "Validating...\n",
            "Current Accuracy: 47.442%\n",
            "Best Accuracy: 47.442%\n",
            "\n",
            "Epoch: [7/50] | Step: [30/196] | Loss: 3.4152\n",
            "Epoch: [7/50] | Step: [60/196] | Loss: 3.6008\n",
            "Epoch: [7/50] | Step: [90/196] | Loss: 3.6969\n",
            "Epoch: [7/50] | Step: [120/196] | Loss: 3.7851\n",
            "Epoch: [7/50] | Step: [150/196] | Loss: 3.9812\n",
            "Epoch: [7/50] | Step: [180/196] | Loss: 3.5203\n",
            "Validating...\n",
            "Current Accuracy: 54.560%\n",
            "Best Accuracy: 54.560%\n",
            "\n",
            "Epoch: [8/50] | Step: [30/196] | Loss: 2.9955\n",
            "Epoch: [8/50] | Step: [60/196] | Loss: 3.0357\n",
            "Epoch: [8/50] | Step: [90/196] | Loss: 3.4464\n",
            "Epoch: [8/50] | Step: [120/196] | Loss: 3.2416\n",
            "Epoch: [8/50] | Step: [150/196] | Loss: 2.9185\n",
            "Epoch: [8/50] | Step: [180/196] | Loss: 3.1059\n",
            "Validating...\n",
            "Current Accuracy: 60.898%\n",
            "Best Accuracy: 60.898%\n",
            "\n",
            "Epoch: [9/50] | Step: [30/196] | Loss: 2.7034\n",
            "Epoch: [9/50] | Step: [60/196] | Loss: 2.7598\n",
            "Epoch: [9/50] | Step: [90/196] | Loss: 2.7605\n",
            "Epoch: [9/50] | Step: [120/196] | Loss: 2.6345\n",
            "Epoch: [9/50] | Step: [150/196] | Loss: 2.9307\n",
            "Epoch: [9/50] | Step: [180/196] | Loss: 3.1463\n",
            "Validating...\n",
            "Current Accuracy: 67.580%\n",
            "Best Accuracy: 67.580%\n",
            "\n",
            "Epoch: [10/50] | Step: [30/196] | Loss: 2.1536\n",
            "Epoch: [10/50] | Step: [60/196] | Loss: 2.0878\n",
            "Epoch: [10/50] | Step: [90/196] | Loss: 2.3634\n",
            "Epoch: [10/50] | Step: [120/196] | Loss: 2.3985\n",
            "Epoch: [10/50] | Step: [150/196] | Loss: 2.7232\n",
            "Epoch: [10/50] | Step: [180/196] | Loss: 2.6237\n",
            "Validating...\n",
            "Current Accuracy: 72.754%\n",
            "Best Accuracy: 72.754%\n",
            "\n",
            "Epoch: [11/50] | Step: [30/196] | Loss: 1.8983\n",
            "Epoch: [11/50] | Step: [60/196] | Loss: 1.9630\n",
            "Epoch: [11/50] | Step: [90/196] | Loss: 2.0645\n",
            "Epoch: [11/50] | Step: [120/196] | Loss: 2.1937\n",
            "Epoch: [11/50] | Step: [150/196] | Loss: 2.1432\n",
            "Epoch: [11/50] | Step: [180/196] | Loss: 1.9972\n",
            "Validating...\n",
            "Current Accuracy: 79.956%\n",
            "Best Accuracy: 79.956%\n",
            "\n",
            "Epoch: [12/50] | Step: [30/196] | Loss: 1.4110\n",
            "Epoch: [12/50] | Step: [60/196] | Loss: 1.5500\n",
            "Epoch: [12/50] | Step: [90/196] | Loss: 1.6154\n",
            "Epoch: [12/50] | Step: [120/196] | Loss: 1.8776\n",
            "Epoch: [12/50] | Step: [150/196] | Loss: 1.8597\n",
            "Epoch: [12/50] | Step: [180/196] | Loss: 2.1827\n",
            "Validating...\n",
            "Current Accuracy: 83.570%\n",
            "Best Accuracy: 83.570%\n",
            "\n",
            "Epoch: [13/50] | Step: [30/196] | Loss: 1.3357\n",
            "Epoch: [13/50] | Step: [60/196] | Loss: 1.3205\n",
            "Epoch: [13/50] | Step: [90/196] | Loss: 1.3287\n",
            "Epoch: [13/50] | Step: [120/196] | Loss: 1.3305\n",
            "Epoch: [13/50] | Step: [150/196] | Loss: 1.4342\n",
            "Epoch: [13/50] | Step: [180/196] | Loss: 1.5118\n",
            "Validating...\n",
            "Current Accuracy: 88.426%\n",
            "Best Accuracy: 88.426%\n",
            "\n",
            "Epoch: [14/50] | Step: [30/196] | Loss: 1.0814\n",
            "Epoch: [14/50] | Step: [60/196] | Loss: 1.2270\n",
            "Epoch: [14/50] | Step: [90/196] | Loss: 1.2794\n",
            "Epoch: [14/50] | Step: [120/196] | Loss: 1.5006\n",
            "Epoch: [14/50] | Step: [150/196] | Loss: 1.1821\n",
            "Epoch: [14/50] | Step: [180/196] | Loss: 1.3362\n",
            "Validating...\n",
            "Current Accuracy: 91.952%\n",
            "Best Accuracy: 91.952%\n",
            "\n",
            "Epoch: [15/50] | Step: [30/196] | Loss: 1.0630\n",
            "Epoch: [15/50] | Step: [60/196] | Loss: 0.8725\n",
            "Epoch: [15/50] | Step: [90/196] | Loss: 0.9866\n",
            "Epoch: [15/50] | Step: [120/196] | Loss: 1.0039\n",
            "Epoch: [15/50] | Step: [150/196] | Loss: 1.0756\n",
            "Epoch: [15/50] | Step: [180/196] | Loss: 1.2116\n",
            "Validating...\n",
            "Current Accuracy: 94.116%\n",
            "Best Accuracy: 94.116%\n",
            "\n",
            "Epoch: [16/50] | Step: [30/196] | Loss: 0.9039\n",
            "Epoch: [16/50] | Step: [60/196] | Loss: 0.7781\n",
            "Epoch: [16/50] | Step: [90/196] | Loss: 0.8277\n",
            "Epoch: [16/50] | Step: [120/196] | Loss: 0.9834\n",
            "Epoch: [16/50] | Step: [150/196] | Loss: 0.8773\n",
            "Epoch: [16/50] | Step: [180/196] | Loss: 1.1252\n",
            "Validating...\n",
            "Current Accuracy: 94.752%\n",
            "Best Accuracy: 94.752%\n",
            "\n",
            "Epoch: [17/50] | Step: [30/196] | Loss: 0.7002\n",
            "Epoch: [17/50] | Step: [60/196] | Loss: 0.7933\n",
            "Epoch: [17/50] | Step: [90/196] | Loss: 0.8238\n",
            "Epoch: [17/50] | Step: [120/196] | Loss: 0.8977\n",
            "Epoch: [17/50] | Step: [150/196] | Loss: 0.7611\n",
            "Epoch: [17/50] | Step: [180/196] | Loss: 0.8962\n",
            "Validating...\n",
            "Current Accuracy: 95.888%\n",
            "Best Accuracy: 95.888%\n",
            "\n",
            "Epoch: [18/50] | Step: [30/196] | Loss: 0.6338\n",
            "Epoch: [18/50] | Step: [60/196] | Loss: 0.7542\n",
            "Epoch: [18/50] | Step: [90/196] | Loss: 0.6568\n",
            "Epoch: [18/50] | Step: [120/196] | Loss: 0.6129\n",
            "Epoch: [18/50] | Step: [150/196] | Loss: 0.7459\n",
            "Epoch: [18/50] | Step: [180/196] | Loss: 0.7828\n",
            "Validating...\n",
            "Current Accuracy: 96.578%\n",
            "Best Accuracy: 96.578%\n",
            "\n",
            "Epoch: [19/50] | Step: [30/196] | Loss: 0.6421\n",
            "Epoch: [19/50] | Step: [60/196] | Loss: 0.5490\n",
            "Epoch: [19/50] | Step: [90/196] | Loss: 0.6578\n",
            "Epoch: [19/50] | Step: [120/196] | Loss: 0.6838\n",
            "Epoch: [19/50] | Step: [150/196] | Loss: 0.6893\n",
            "Epoch: [19/50] | Step: [180/196] | Loss: 0.6524\n",
            "Validating...\n",
            "Current Accuracy: 97.434%\n",
            "Best Accuracy: 97.434%\n",
            "\n",
            "Epoch: [20/50] | Step: [30/196] | Loss: 0.5446\n",
            "Epoch: [20/50] | Step: [60/196] | Loss: 0.6965\n",
            "Epoch: [20/50] | Step: [90/196] | Loss: 0.5591\n",
            "Epoch: [20/50] | Step: [120/196] | Loss: 0.5627\n",
            "Epoch: [20/50] | Step: [150/196] | Loss: 0.6339\n",
            "Epoch: [20/50] | Step: [180/196] | Loss: 0.7074\n",
            "Validating...\n",
            "Current Accuracy: 97.686%\n",
            "Best Accuracy: 97.686%\n",
            "\n",
            "Epoch: [21/50] | Step: [30/196] | Loss: 0.4992\n",
            "Epoch: [21/50] | Step: [60/196] | Loss: 0.5608\n",
            "Epoch: [21/50] | Step: [90/196] | Loss: 0.5614\n",
            "Epoch: [21/50] | Step: [120/196] | Loss: 0.4937\n",
            "Epoch: [21/50] | Step: [150/196] | Loss: 0.6345\n",
            "Epoch: [21/50] | Step: [180/196] | Loss: 0.5265\n",
            "Validating...\n",
            "Current Accuracy: 97.486%\n",
            "Best Accuracy: 97.686%\n",
            "\n",
            "Epoch: [22/50] | Step: [30/196] | Loss: 0.5813\n",
            "Epoch: [22/50] | Step: [60/196] | Loss: 0.4145\n",
            "Epoch: [22/50] | Step: [90/196] | Loss: 0.3777\n",
            "Epoch: [22/50] | Step: [120/196] | Loss: 0.4940\n",
            "Epoch: [22/50] | Step: [150/196] | Loss: 0.4726\n",
            "Epoch: [22/50] | Step: [180/196] | Loss: 0.5215\n",
            "Validating...\n",
            "Current Accuracy: 97.606%\n",
            "Best Accuracy: 97.686%\n",
            "\n",
            "Epoch: [23/50] | Step: [30/196] | Loss: 0.4235\n",
            "Epoch: [23/50] | Step: [60/196] | Loss: 0.4444\n",
            "Epoch: [23/50] | Step: [90/196] | Loss: 0.4045\n",
            "Epoch: [23/50] | Step: [120/196] | Loss: 0.4270\n",
            "Epoch: [23/50] | Step: [150/196] | Loss: 0.4309\n",
            "Epoch: [23/50] | Step: [180/196] | Loss: 0.5314\n",
            "Validating...\n",
            "Current Accuracy: 97.434%\n",
            "Best Accuracy: 97.686%\n",
            "\n",
            "Epoch: [24/50] | Step: [30/196] | Loss: 0.5417\n",
            "Epoch: [24/50] | Step: [60/196] | Loss: 0.4315\n",
            "Epoch: [24/50] | Step: [90/196] | Loss: 0.6694\n",
            "Epoch: [24/50] | Step: [120/196] | Loss: 0.5106\n",
            "Epoch: [24/50] | Step: [150/196] | Loss: 0.4009\n",
            "Epoch: [24/50] | Step: [180/196] | Loss: 0.6836\n",
            "Validating...\n",
            "Current Accuracy: 96.228%\n",
            "Best Accuracy: 97.686%\n",
            "\n",
            "Epoch: [25/50] | Step: [30/196] | Loss: 0.4506\n",
            "Epoch: [25/50] | Step: [60/196] | Loss: 0.4420\n",
            "Epoch: [25/50] | Step: [90/196] | Loss: 0.4150\n",
            "Epoch: [25/50] | Step: [120/196] | Loss: 0.3684\n",
            "Epoch: [25/50] | Step: [150/196] | Loss: 0.4225\n",
            "Epoch: [25/50] | Step: [180/196] | Loss: 0.4311\n",
            "Validating...\n",
            "Current Accuracy: 97.718%\n",
            "Best Accuracy: 97.718%\n",
            "\n",
            "Epoch: [26/50] | Step: [30/196] | Loss: 0.4222\n",
            "Epoch: [26/50] | Step: [60/196] | Loss: 0.4838\n",
            "Epoch: [26/50] | Step: [90/196] | Loss: 0.5207\n",
            "Epoch: [26/50] | Step: [120/196] | Loss: 0.4043\n",
            "Epoch: [26/50] | Step: [150/196] | Loss: 0.4090\n",
            "Epoch: [26/50] | Step: [180/196] | Loss: 0.4159\n",
            "Validating...\n",
            "Current Accuracy: 97.648%\n",
            "Best Accuracy: 97.718%\n",
            "\n",
            "Epoch: [27/50] | Step: [30/196] | Loss: 0.3627\n",
            "Epoch: [27/50] | Step: [60/196] | Loss: 0.3702\n",
            "Epoch: [27/50] | Step: [90/196] | Loss: 0.3775\n",
            "Epoch: [27/50] | Step: [120/196] | Loss: 0.3176\n",
            "Epoch: [27/50] | Step: [150/196] | Loss: 0.3161\n",
            "Epoch: [27/50] | Step: [180/196] | Loss: 0.4918\n",
            "Validating...\n",
            "Current Accuracy: 98.158%\n",
            "Best Accuracy: 98.158%\n",
            "\n",
            "Epoch: [28/50] | Step: [30/196] | Loss: 0.4712\n",
            "Epoch: [28/50] | Step: [60/196] | Loss: 0.3938\n",
            "Epoch: [28/50] | Step: [90/196] | Loss: 0.3575\n",
            "Epoch: [28/50] | Step: [120/196] | Loss: 0.4155\n",
            "Epoch: [28/50] | Step: [150/196] | Loss: 0.3949\n",
            "Epoch: [28/50] | Step: [180/196] | Loss: 0.3165\n",
            "Validating...\n",
            "Current Accuracy: 98.330%\n",
            "Best Accuracy: 98.330%\n",
            "\n",
            "Epoch: [29/50] | Step: [30/196] | Loss: 0.2806\n",
            "Epoch: [29/50] | Step: [60/196] | Loss: 0.3056\n",
            "Epoch: [29/50] | Step: [90/196] | Loss: 0.3897\n",
            "Epoch: [29/50] | Step: [120/196] | Loss: 0.3103\n",
            "Epoch: [29/50] | Step: [150/196] | Loss: 0.3524\n",
            "Epoch: [29/50] | Step: [180/196] | Loss: 0.3619\n",
            "Validating...\n",
            "Current Accuracy: 98.532%\n",
            "Best Accuracy: 98.532%\n",
            "\n",
            "Epoch: [30/50] | Step: [30/196] | Loss: 0.3172\n",
            "Epoch: [30/50] | Step: [60/196] | Loss: 0.4032\n",
            "Epoch: [30/50] | Step: [90/196] | Loss: 0.3013\n",
            "Epoch: [30/50] | Step: [120/196] | Loss: 0.3315\n",
            "Epoch: [30/50] | Step: [150/196] | Loss: 0.3240\n",
            "Epoch: [30/50] | Step: [180/196] | Loss: 0.4287\n",
            "Validating...\n",
            "Current Accuracy: 98.430%\n",
            "Best Accuracy: 98.532%\n",
            "\n",
            "Epoch: [31/50] | Step: [30/196] | Loss: 0.3242\n",
            "Epoch: [31/50] | Step: [60/196] | Loss: 0.3903\n",
            "Epoch: [31/50] | Step: [90/196] | Loss: 0.2717\n",
            "Epoch: [31/50] | Step: [120/196] | Loss: 0.3146\n",
            "Epoch: [31/50] | Step: [150/196] | Loss: 0.4281\n",
            "Epoch: [31/50] | Step: [180/196] | Loss: 0.4092\n",
            "Validating...\n",
            "Current Accuracy: 97.888%\n",
            "Best Accuracy: 98.532%\n",
            "\n",
            "Epoch: [32/50] | Step: [30/196] | Loss: 0.4545\n",
            "Epoch: [32/50] | Step: [60/196] | Loss: 0.2682\n",
            "Epoch: [32/50] | Step: [90/196] | Loss: 0.4035\n",
            "Epoch: [32/50] | Step: [120/196] | Loss: 0.3420\n",
            "Epoch: [32/50] | Step: [150/196] | Loss: 0.4651\n",
            "Epoch: [32/50] | Step: [180/196] | Loss: 0.3359\n",
            "Validating...\n",
            "Current Accuracy: 98.326%\n",
            "Best Accuracy: 98.532%\n",
            "\n",
            "Epoch: [33/50] | Step: [30/196] | Loss: 0.2318\n",
            "Epoch: [33/50] | Step: [60/196] | Loss: 0.4091\n",
            "Epoch: [33/50] | Step: [90/196] | Loss: 0.4002\n",
            "Epoch: [33/50] | Step: [120/196] | Loss: 0.3127\n",
            "Epoch: [33/50] | Step: [150/196] | Loss: 0.2423\n",
            "Epoch: [33/50] | Step: [180/196] | Loss: 0.3293\n",
            "Validating...\n",
            "Current Accuracy: 98.358%\n",
            "Best Accuracy: 98.532%\n",
            "\n",
            "Epoch: [34/50] | Step: [30/196] | Loss: 0.3760\n",
            "Epoch: [34/50] | Step: [60/196] | Loss: 0.2597\n",
            "Epoch: [34/50] | Step: [90/196] | Loss: 0.4026\n",
            "Epoch: [34/50] | Step: [120/196] | Loss: 0.2564\n",
            "Epoch: [34/50] | Step: [150/196] | Loss: 0.3749\n",
            "Epoch: [34/50] | Step: [180/196] | Loss: 0.2865\n",
            "Validating...\n",
            "Current Accuracy: 98.422%\n",
            "Best Accuracy: 98.532%\n",
            "\n",
            "Epoch: [35/50] | Step: [30/196] | Loss: 0.2579\n",
            "Epoch: [35/50] | Step: [60/196] | Loss: 0.2273\n",
            "Epoch: [35/50] | Step: [90/196] | Loss: 0.2718\n",
            "Epoch: [35/50] | Step: [120/196] | Loss: 0.3322\n",
            "Epoch: [35/50] | Step: [150/196] | Loss: 0.2180\n",
            "Epoch: [35/50] | Step: [180/196] | Loss: 0.2478\n",
            "Validating...\n",
            "Current Accuracy: 98.670%\n",
            "Best Accuracy: 98.670%\n",
            "\n",
            "Epoch: [36/50] | Step: [30/196] | Loss: 0.2299\n",
            "Epoch: [36/50] | Step: [60/196] | Loss: 0.2083\n",
            "Epoch: [36/50] | Step: [90/196] | Loss: 0.3249\n",
            "Epoch: [36/50] | Step: [120/196] | Loss: 0.2337\n",
            "Epoch: [36/50] | Step: [150/196] | Loss: 0.2993\n",
            "Epoch: [36/50] | Step: [180/196] | Loss: 0.2123\n",
            "Validating...\n",
            "Current Accuracy: 98.682%\n",
            "Best Accuracy: 98.682%\n",
            "\n",
            "Epoch: [37/50] | Step: [30/196] | Loss: 0.3241\n",
            "Epoch: [37/50] | Step: [60/196] | Loss: 0.1991\n",
            "Epoch: [37/50] | Step: [90/196] | Loss: 0.2172\n",
            "Epoch: [37/50] | Step: [120/196] | Loss: 0.2914\n",
            "Epoch: [37/50] | Step: [150/196] | Loss: 0.3519\n",
            "Epoch: [37/50] | Step: [180/196] | Loss: 0.2616\n",
            "Validating...\n",
            "Current Accuracy: 98.758%\n",
            "Best Accuracy: 98.758%\n",
            "\n",
            "Epoch: [38/50] | Step: [30/196] | Loss: 0.1832\n",
            "Epoch: [38/50] | Step: [60/196] | Loss: 0.2067\n",
            "Epoch: [38/50] | Step: [90/196] | Loss: 0.1418\n",
            "Epoch: [38/50] | Step: [120/196] | Loss: 0.1606\n",
            "Epoch: [38/50] | Step: [150/196] | Loss: 0.2030\n",
            "Epoch: [38/50] | Step: [180/196] | Loss: 0.2142\n",
            "Validating...\n",
            "Current Accuracy: 98.654%\n",
            "Best Accuracy: 98.758%\n",
            "\n",
            "Epoch: [39/50] | Step: [30/196] | Loss: 0.1921\n",
            "Epoch: [39/50] | Step: [60/196] | Loss: 0.2089\n",
            "Epoch: [39/50] | Step: [90/196] | Loss: 0.1519\n",
            "Epoch: [39/50] | Step: [120/196] | Loss: 0.2666\n",
            "Epoch: [39/50] | Step: [150/196] | Loss: 0.2366\n",
            "Epoch: [39/50] | Step: [180/196] | Loss: 0.2247\n",
            "Validating...\n",
            "Current Accuracy: 98.040%\n",
            "Best Accuracy: 98.758%\n",
            "\n",
            "Epoch: [40/50] | Step: [30/196] | Loss: 0.1879\n",
            "Epoch: [40/50] | Step: [60/196] | Loss: 0.2187\n",
            "Epoch: [40/50] | Step: [90/196] | Loss: 0.2205\n",
            "Epoch: [40/50] | Step: [120/196] | Loss: 0.2942\n",
            "Epoch: [40/50] | Step: [150/196] | Loss: 0.2714\n",
            "Epoch: [40/50] | Step: [180/196] | Loss: 0.2637\n",
            "Validating...\n",
            "Current Accuracy: 97.924%\n",
            "Best Accuracy: 98.758%\n",
            "\n",
            "Epoch: [41/50] | Step: [30/196] | Loss: 0.4016\n",
            "Epoch: [41/50] | Step: [60/196] | Loss: 0.3029\n",
            "Epoch: [41/50] | Step: [90/196] | Loss: 0.3125\n",
            "Epoch: [41/50] | Step: [120/196] | Loss: 0.5442\n",
            "Epoch: [41/50] | Step: [150/196] | Loss: 0.3375\n",
            "Epoch: [41/50] | Step: [180/196] | Loss: 0.2591\n",
            "Validating...\n",
            "Current Accuracy: 97.452%\n",
            "Best Accuracy: 98.758%\n",
            "\n",
            "Epoch: [42/50] | Step: [30/196] | Loss: 0.2690\n",
            "Epoch: [42/50] | Step: [60/196] | Loss: 0.2736\n",
            "Epoch: [42/50] | Step: [90/196] | Loss: 0.2527\n",
            "Epoch: [42/50] | Step: [120/196] | Loss: 0.2578\n",
            "Epoch: [42/50] | Step: [150/196] | Loss: 0.2451\n",
            "Epoch: [42/50] | Step: [180/196] | Loss: 0.2556\n",
            "Validating...\n",
            "Current Accuracy: 98.400%\n",
            "Best Accuracy: 98.758%\n",
            "\n",
            "Epoch: [43/50] | Step: [30/196] | Loss: 0.1694\n",
            "Epoch: [43/50] | Step: [60/196] | Loss: 0.2055\n",
            "Epoch: [43/50] | Step: [90/196] | Loss: 0.1997\n",
            "Epoch: [43/50] | Step: [120/196] | Loss: 0.2094\n",
            "Epoch: [43/50] | Step: [150/196] | Loss: 0.1722\n",
            "Epoch: [43/50] | Step: [180/196] | Loss: 0.1662\n",
            "Validating...\n",
            "Current Accuracy: 99.138%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Epoch: [44/50] | Step: [30/196] | Loss: 0.1438\n",
            "Epoch: [44/50] | Step: [60/196] | Loss: 0.1938\n",
            "Epoch: [44/50] | Step: [90/196] | Loss: 0.1400\n",
            "Epoch: [44/50] | Step: [120/196] | Loss: 0.1563\n",
            "Epoch: [44/50] | Step: [150/196] | Loss: 0.1450\n",
            "Epoch: [44/50] | Step: [180/196] | Loss: 0.1790\n",
            "Validating...\n",
            "Current Accuracy: 99.128%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Epoch: [45/50] | Step: [30/196] | Loss: 0.2456\n",
            "Epoch: [45/50] | Step: [60/196] | Loss: 0.1723\n",
            "Epoch: [45/50] | Step: [90/196] | Loss: 0.1523\n",
            "Epoch: [45/50] | Step: [120/196] | Loss: 0.2299\n",
            "Epoch: [45/50] | Step: [150/196] | Loss: 0.2311\n",
            "Epoch: [45/50] | Step: [180/196] | Loss: 0.1657\n",
            "Validating...\n",
            "Current Accuracy: 98.436%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Epoch: [46/50] | Step: [30/196] | Loss: 0.1410\n",
            "Epoch: [46/50] | Step: [60/196] | Loss: 0.2500\n",
            "Epoch: [46/50] | Step: [90/196] | Loss: 0.1899\n",
            "Epoch: [46/50] | Step: [120/196] | Loss: 0.1573\n",
            "Epoch: [46/50] | Step: [150/196] | Loss: 0.2511\n",
            "Epoch: [46/50] | Step: [180/196] | Loss: 0.3721\n",
            "Validating...\n",
            "Current Accuracy: 98.450%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Epoch: [47/50] | Step: [30/196] | Loss: 0.1569\n",
            "Epoch: [47/50] | Step: [60/196] | Loss: 0.2367\n",
            "Epoch: [47/50] | Step: [90/196] | Loss: 0.3080\n",
            "Epoch: [47/50] | Step: [120/196] | Loss: 0.2785\n",
            "Epoch: [47/50] | Step: [150/196] | Loss: 0.1864\n",
            "Epoch: [47/50] | Step: [180/196] | Loss: 0.1935\n",
            "Validating...\n",
            "Current Accuracy: 98.922%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Epoch: [48/50] | Step: [30/196] | Loss: 0.1976\n",
            "Epoch: [48/50] | Step: [60/196] | Loss: 0.1308\n",
            "Epoch: [48/50] | Step: [90/196] | Loss: 0.1157\n",
            "Epoch: [48/50] | Step: [120/196] | Loss: 0.2785\n",
            "Epoch: [48/50] | Step: [150/196] | Loss: 0.1906\n",
            "Epoch: [48/50] | Step: [180/196] | Loss: 0.2100\n",
            "Validating...\n",
            "Current Accuracy: 98.900%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Epoch: [49/50] | Step: [30/196] | Loss: 0.2093\n",
            "Epoch: [49/50] | Step: [60/196] | Loss: 0.1882\n",
            "Epoch: [49/50] | Step: [90/196] | Loss: 0.1786\n",
            "Epoch: [49/50] | Step: [120/196] | Loss: 0.2563\n",
            "Epoch: [49/50] | Step: [150/196] | Loss: 0.1556\n",
            "Epoch: [49/50] | Step: [180/196] | Loss: 0.2062\n",
            "Validating...\n",
            "Current Accuracy: 98.796%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Epoch: [50/50] | Step: [30/196] | Loss: 0.1158\n",
            "Epoch: [50/50] | Step: [60/196] | Loss: 0.2222\n",
            "Epoch: [50/50] | Step: [90/196] | Loss: 0.1458\n",
            "Epoch: [50/50] | Step: [120/196] | Loss: 0.1433\n",
            "Epoch: [50/50] | Step: [150/196] | Loss: 0.1958\n",
            "Epoch: [50/50] | Step: [180/196] | Loss: 0.1670\n",
            "Validating...\n",
            "Current Accuracy: 99.000%\n",
            "Best Accuracy: 99.138%\n",
            "\n",
            "Train Finished!\n"
          ]
        }
      ],
      "source": [
        "train(model=model1, optimizer=optimizer1, train_loader=train_loader, val_loader=valid_loader, criterion=criterion1, total_epochs=total_epochs,name=\"model_cbam\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(model=model2, optimizer=optimizer2, train_loader=train_loader, val_loader=valid_loader, criterion=criterion2, total_epochs=total_epochs,name=\"model_without_cbam\")"
      ],
      "metadata": {
        "id": "ehfLkqXsSJDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94be316f-4264-406c-f716-4c55e567f523"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Begin!\n",
            "\n",
            "Epoch: [1/50] | Step: [30/196] | Loss: 7.3109\n",
            "Epoch: [1/50] | Step: [60/196] | Loss: 6.9753\n",
            "Epoch: [1/50] | Step: [90/196] | Loss: 6.8671\n",
            "Epoch: [1/50] | Step: [120/196] | Loss: 6.6637\n",
            "Epoch: [1/50] | Step: [150/196] | Loss: 6.6039\n",
            "Epoch: [1/50] | Step: [180/196] | Loss: 6.3111\n",
            "Validating...\n",
            "Current Accuracy: 12.968%\n",
            "Best Accuracy: 12.968%\n",
            "\n",
            "Epoch: [2/50] | Step: [30/196] | Loss: 6.2543\n",
            "Epoch: [2/50] | Step: [60/196] | Loss: 5.9375\n",
            "Epoch: [2/50] | Step: [90/196] | Loss: 5.8822\n",
            "Epoch: [2/50] | Step: [120/196] | Loss: 5.9700\n",
            "Epoch: [2/50] | Step: [150/196] | Loss: 5.8076\n",
            "Epoch: [2/50] | Step: [180/196] | Loss: 5.5451\n",
            "Validating...\n",
            "Current Accuracy: 21.000%\n",
            "Best Accuracy: 21.000%\n",
            "\n",
            "Epoch: [3/50] | Step: [30/196] | Loss: 5.3566\n",
            "Epoch: [3/50] | Step: [60/196] | Loss: 5.2868\n",
            "Epoch: [3/50] | Step: [90/196] | Loss: 5.5324\n",
            "Epoch: [3/50] | Step: [120/196] | Loss: 5.4339\n",
            "Epoch: [3/50] | Step: [150/196] | Loss: 5.2963\n",
            "Epoch: [3/50] | Step: [180/196] | Loss: 5.0945\n",
            "Validating...\n",
            "Current Accuracy: 27.248%\n",
            "Best Accuracy: 27.248%\n",
            "\n",
            "Epoch: [4/50] | Step: [30/196] | Loss: 5.0185\n",
            "Epoch: [4/50] | Step: [60/196] | Loss: 4.4996\n",
            "Epoch: [4/50] | Step: [90/196] | Loss: 4.9273\n",
            "Epoch: [4/50] | Step: [120/196] | Loss: 4.7196\n",
            "Epoch: [4/50] | Step: [150/196] | Loss: 4.9989\n",
            "Epoch: [4/50] | Step: [180/196] | Loss: 4.7716\n",
            "Validating...\n",
            "Current Accuracy: 33.466%\n",
            "Best Accuracy: 33.466%\n",
            "\n",
            "Epoch: [5/50] | Step: [30/196] | Loss: 4.4129\n",
            "Epoch: [5/50] | Step: [60/196] | Loss: 4.3037\n",
            "Epoch: [5/50] | Step: [90/196] | Loss: 4.6153\n",
            "Epoch: [5/50] | Step: [120/196] | Loss: 4.6493\n",
            "Epoch: [5/50] | Step: [150/196] | Loss: 4.4270\n",
            "Epoch: [5/50] | Step: [180/196] | Loss: 4.4076\n",
            "Validating...\n",
            "Current Accuracy: 39.134%\n",
            "Best Accuracy: 39.134%\n",
            "\n",
            "Epoch: [6/50] | Step: [30/196] | Loss: 3.6372\n",
            "Epoch: [6/50] | Step: [60/196] | Loss: 3.9522\n",
            "Epoch: [6/50] | Step: [90/196] | Loss: 4.0876\n",
            "Epoch: [6/50] | Step: [120/196] | Loss: 4.0499\n",
            "Epoch: [6/50] | Step: [150/196] | Loss: 4.2531\n",
            "Epoch: [6/50] | Step: [180/196] | Loss: 4.2161\n",
            "Validating...\n",
            "Current Accuracy: 45.270%\n",
            "Best Accuracy: 45.270%\n",
            "\n",
            "Epoch: [7/50] | Step: [30/196] | Loss: 3.4873\n",
            "Epoch: [7/50] | Step: [60/196] | Loss: 3.7131\n",
            "Epoch: [7/50] | Step: [90/196] | Loss: 3.7869\n",
            "Epoch: [7/50] | Step: [120/196] | Loss: 3.4638\n",
            "Epoch: [7/50] | Step: [150/196] | Loss: 3.8392\n",
            "Epoch: [7/50] | Step: [180/196] | Loss: 3.8087\n",
            "Validating...\n",
            "Current Accuracy: 52.116%\n",
            "Best Accuracy: 52.116%\n",
            "\n",
            "Epoch: [8/50] | Step: [30/196] | Loss: 3.1950\n",
            "Epoch: [8/50] | Step: [60/196] | Loss: 3.1882\n",
            "Epoch: [8/50] | Step: [90/196] | Loss: 3.1911\n",
            "Epoch: [8/50] | Step: [120/196] | Loss: 3.3640\n",
            "Epoch: [8/50] | Step: [150/196] | Loss: 3.4207\n",
            "Epoch: [8/50] | Step: [180/196] | Loss: 3.2945\n",
            "Validating...\n",
            "Current Accuracy: 59.250%\n",
            "Best Accuracy: 59.250%\n",
            "\n",
            "Epoch: [9/50] | Step: [30/196] | Loss: 3.0240\n",
            "Epoch: [9/50] | Step: [60/196] | Loss: 2.9430\n",
            "Epoch: [9/50] | Step: [90/196] | Loss: 3.1261\n",
            "Epoch: [9/50] | Step: [120/196] | Loss: 3.0641\n",
            "Epoch: [9/50] | Step: [150/196] | Loss: 2.8521\n",
            "Epoch: [9/50] | Step: [180/196] | Loss: 3.1049\n",
            "Validating...\n",
            "Current Accuracy: 65.684%\n",
            "Best Accuracy: 65.684%\n",
            "\n",
            "Epoch: [10/50] | Step: [30/196] | Loss: 2.5805\n",
            "Epoch: [10/50] | Step: [60/196] | Loss: 2.5836\n",
            "Epoch: [10/50] | Step: [90/196] | Loss: 2.6562\n",
            "Epoch: [10/50] | Step: [120/196] | Loss: 2.7088\n",
            "Epoch: [10/50] | Step: [150/196] | Loss: 2.3911\n",
            "Epoch: [10/50] | Step: [180/196] | Loss: 2.6689\n",
            "Validating...\n",
            "Current Accuracy: 69.890%\n",
            "Best Accuracy: 69.890%\n",
            "\n",
            "Epoch: [11/50] | Step: [30/196] | Loss: 2.1955\n",
            "Epoch: [11/50] | Step: [60/196] | Loss: 2.1322\n",
            "Epoch: [11/50] | Step: [90/196] | Loss: 2.3794\n",
            "Epoch: [11/50] | Step: [120/196] | Loss: 2.2303\n",
            "Epoch: [11/50] | Step: [150/196] | Loss: 2.2446\n",
            "Epoch: [11/50] | Step: [180/196] | Loss: 2.5201\n",
            "Validating...\n",
            "Current Accuracy: 77.586%\n",
            "Best Accuracy: 77.586%\n",
            "\n",
            "Epoch: [12/50] | Step: [30/196] | Loss: 1.6972\n",
            "Epoch: [12/50] | Step: [60/196] | Loss: 1.6981\n",
            "Epoch: [12/50] | Step: [90/196] | Loss: 2.0008\n",
            "Epoch: [12/50] | Step: [120/196] | Loss: 2.0638\n",
            "Epoch: [12/50] | Step: [150/196] | Loss: 2.0113\n",
            "Epoch: [12/50] | Step: [180/196] | Loss: 1.9852\n",
            "Validating...\n",
            "Current Accuracy: 82.418%\n",
            "Best Accuracy: 82.418%\n",
            "\n",
            "Epoch: [13/50] | Step: [30/196] | Loss: 1.5536\n",
            "Epoch: [13/50] | Step: [60/196] | Loss: 1.3741\n",
            "Epoch: [13/50] | Step: [90/196] | Loss: 1.5279\n",
            "Epoch: [13/50] | Step: [120/196] | Loss: 1.5167\n",
            "Epoch: [13/50] | Step: [150/196] | Loss: 1.7965\n",
            "Epoch: [13/50] | Step: [180/196] | Loss: 1.7031\n",
            "Validating...\n",
            "Current Accuracy: 87.788%\n",
            "Best Accuracy: 87.788%\n",
            "\n",
            "Epoch: [14/50] | Step: [30/196] | Loss: 1.3085\n",
            "Epoch: [14/50] | Step: [60/196] | Loss: 1.3910\n",
            "Epoch: [14/50] | Step: [90/196] | Loss: 1.3429\n",
            "Epoch: [14/50] | Step: [120/196] | Loss: 1.3193\n",
            "Epoch: [14/50] | Step: [150/196] | Loss: 1.4897\n",
            "Epoch: [14/50] | Step: [180/196] | Loss: 1.5191\n",
            "Validating...\n",
            "Current Accuracy: 89.372%\n",
            "Best Accuracy: 89.372%\n",
            "\n",
            "Epoch: [15/50] | Step: [30/196] | Loss: 1.0310\n",
            "Epoch: [15/50] | Step: [60/196] | Loss: 0.9073\n",
            "Epoch: [15/50] | Step: [90/196] | Loss: 1.1710\n",
            "Epoch: [15/50] | Step: [120/196] | Loss: 1.1505\n",
            "Epoch: [15/50] | Step: [150/196] | Loss: 1.2460\n",
            "Epoch: [15/50] | Step: [180/196] | Loss: 1.2872\n",
            "Validating...\n",
            "Current Accuracy: 92.726%\n",
            "Best Accuracy: 92.726%\n",
            "\n",
            "Epoch: [16/50] | Step: [30/196] | Loss: 0.8830\n",
            "Epoch: [16/50] | Step: [60/196] | Loss: 0.9565\n",
            "Epoch: [16/50] | Step: [90/196] | Loss: 0.9857\n",
            "Epoch: [16/50] | Step: [120/196] | Loss: 0.9520\n",
            "Epoch: [16/50] | Step: [150/196] | Loss: 1.0849\n",
            "Epoch: [16/50] | Step: [180/196] | Loss: 0.9278\n",
            "Validating...\n",
            "Current Accuracy: 95.144%\n",
            "Best Accuracy: 95.144%\n",
            "\n",
            "Epoch: [17/50] | Step: [30/196] | Loss: 1.0277\n",
            "Epoch: [17/50] | Step: [60/196] | Loss: 0.6901\n",
            "Epoch: [17/50] | Step: [90/196] | Loss: 0.8112\n",
            "Epoch: [17/50] | Step: [120/196] | Loss: 0.7997\n",
            "Epoch: [17/50] | Step: [150/196] | Loss: 0.9678\n",
            "Epoch: [17/50] | Step: [180/196] | Loss: 0.9101\n",
            "Validating...\n",
            "Current Accuracy: 95.430%\n",
            "Best Accuracy: 95.430%\n",
            "\n",
            "Epoch: [18/50] | Step: [30/196] | Loss: 0.8025\n",
            "Epoch: [18/50] | Step: [60/196] | Loss: 0.5994\n",
            "Epoch: [18/50] | Step: [90/196] | Loss: 0.6839\n",
            "Epoch: [18/50] | Step: [120/196] | Loss: 0.7245\n",
            "Epoch: [18/50] | Step: [150/196] | Loss: 0.7949\n",
            "Epoch: [18/50] | Step: [180/196] | Loss: 0.9055\n",
            "Validating...\n",
            "Current Accuracy: 96.756%\n",
            "Best Accuracy: 96.756%\n",
            "\n",
            "Epoch: [19/50] | Step: [30/196] | Loss: 0.5327\n",
            "Epoch: [19/50] | Step: [60/196] | Loss: 0.6384\n",
            "Epoch: [19/50] | Step: [90/196] | Loss: 0.6346\n",
            "Epoch: [19/50] | Step: [120/196] | Loss: 0.6751\n",
            "Epoch: [19/50] | Step: [150/196] | Loss: 0.7506\n",
            "Epoch: [19/50] | Step: [180/196] | Loss: 0.6788\n",
            "Validating...\n",
            "Current Accuracy: 97.320%\n",
            "Best Accuracy: 97.320%\n",
            "\n",
            "Epoch: [20/50] | Step: [30/196] | Loss: 0.4712\n",
            "Epoch: [20/50] | Step: [60/196] | Loss: 0.4799\n",
            "Epoch: [20/50] | Step: [90/196] | Loss: 0.6037\n",
            "Epoch: [20/50] | Step: [120/196] | Loss: 0.5839\n",
            "Epoch: [20/50] | Step: [150/196] | Loss: 0.6748\n",
            "Epoch: [20/50] | Step: [180/196] | Loss: 0.6870\n",
            "Validating...\n",
            "Current Accuracy: 97.414%\n",
            "Best Accuracy: 97.414%\n",
            "\n",
            "Epoch: [21/50] | Step: [30/196] | Loss: 0.4908\n",
            "Epoch: [21/50] | Step: [60/196] | Loss: 0.6501\n",
            "Epoch: [21/50] | Step: [90/196] | Loss: 0.5422\n",
            "Epoch: [21/50] | Step: [120/196] | Loss: 0.5440\n",
            "Epoch: [21/50] | Step: [150/196] | Loss: 0.6135\n",
            "Epoch: [21/50] | Step: [180/196] | Loss: 0.6773\n",
            "Validating...\n",
            "Current Accuracy: 97.380%\n",
            "Best Accuracy: 97.414%\n",
            "\n",
            "Epoch: [22/50] | Step: [30/196] | Loss: 0.4799\n",
            "Epoch: [22/50] | Step: [60/196] | Loss: 0.4624\n",
            "Epoch: [22/50] | Step: [90/196] | Loss: 0.5099\n",
            "Epoch: [22/50] | Step: [120/196] | Loss: 0.5477\n",
            "Epoch: [22/50] | Step: [150/196] | Loss: 0.5152\n",
            "Epoch: [22/50] | Step: [180/196] | Loss: 0.6127\n",
            "Validating...\n",
            "Current Accuracy: 97.088%\n",
            "Best Accuracy: 97.414%\n",
            "\n",
            "Epoch: [23/50] | Step: [30/196] | Loss: 0.4463\n",
            "Epoch: [23/50] | Step: [60/196] | Loss: 0.4881\n",
            "Epoch: [23/50] | Step: [90/196] | Loss: 0.4914\n",
            "Epoch: [23/50] | Step: [120/196] | Loss: 0.4977\n",
            "Epoch: [23/50] | Step: [150/196] | Loss: 0.4304\n",
            "Epoch: [23/50] | Step: [180/196] | Loss: 0.5846\n",
            "Validating...\n",
            "Current Accuracy: 97.836%\n",
            "Best Accuracy: 97.836%\n",
            "\n",
            "Epoch: [24/50] | Step: [30/196] | Loss: 0.4709\n",
            "Epoch: [24/50] | Step: [60/196] | Loss: 0.6732\n",
            "Epoch: [24/50] | Step: [90/196] | Loss: 0.4399\n",
            "Epoch: [24/50] | Step: [120/196] | Loss: 0.4651\n",
            "Epoch: [24/50] | Step: [150/196] | Loss: 0.5541\n",
            "Epoch: [24/50] | Step: [180/196] | Loss: 0.5916\n",
            "Validating...\n",
            "Current Accuracy: 97.418%\n",
            "Best Accuracy: 97.836%\n",
            "\n",
            "Epoch: [25/50] | Step: [30/196] | Loss: 0.3915\n",
            "Epoch: [25/50] | Step: [60/196] | Loss: 0.4720\n",
            "Epoch: [25/50] | Step: [90/196] | Loss: 0.4210\n",
            "Epoch: [25/50] | Step: [120/196] | Loss: 0.4403\n",
            "Epoch: [25/50] | Step: [150/196] | Loss: 0.4834\n",
            "Epoch: [25/50] | Step: [180/196] | Loss: 0.7485\n",
            "Validating...\n",
            "Current Accuracy: 97.058%\n",
            "Best Accuracy: 97.836%\n",
            "\n",
            "Epoch: [26/50] | Step: [30/196] | Loss: 0.5297\n",
            "Epoch: [26/50] | Step: [60/196] | Loss: 0.5502\n",
            "Epoch: [26/50] | Step: [90/196] | Loss: 0.4667\n",
            "Epoch: [26/50] | Step: [120/196] | Loss: 0.5346\n",
            "Epoch: [26/50] | Step: [150/196] | Loss: 0.4411\n",
            "Epoch: [26/50] | Step: [180/196] | Loss: 0.6613\n",
            "Validating...\n",
            "Current Accuracy: 97.038%\n",
            "Best Accuracy: 97.836%\n",
            "\n",
            "Epoch: [27/50] | Step: [30/196] | Loss: 0.3711\n",
            "Epoch: [27/50] | Step: [60/196] | Loss: 0.3745\n",
            "Epoch: [27/50] | Step: [90/196] | Loss: 0.3740\n",
            "Epoch: [27/50] | Step: [120/196] | Loss: 0.4148\n",
            "Epoch: [27/50] | Step: [150/196] | Loss: 0.5092\n",
            "Epoch: [27/50] | Step: [180/196] | Loss: 0.4846\n",
            "Validating...\n",
            "Current Accuracy: 97.900%\n",
            "Best Accuracy: 97.900%\n",
            "\n",
            "Epoch: [28/50] | Step: [30/196] | Loss: 0.4094\n",
            "Epoch: [28/50] | Step: [60/196] | Loss: 0.3852\n",
            "Epoch: [28/50] | Step: [90/196] | Loss: 0.3310\n",
            "Epoch: [28/50] | Step: [120/196] | Loss: 0.4164\n",
            "Epoch: [28/50] | Step: [150/196] | Loss: 0.4604\n",
            "Epoch: [28/50] | Step: [180/196] | Loss: 0.4647\n",
            "Validating...\n",
            "Current Accuracy: 98.452%\n",
            "Best Accuracy: 98.452%\n",
            "\n",
            "Epoch: [29/50] | Step: [30/196] | Loss: 0.3410\n",
            "Epoch: [29/50] | Step: [60/196] | Loss: 0.2591\n",
            "Epoch: [29/50] | Step: [90/196] | Loss: 0.3210\n",
            "Epoch: [29/50] | Step: [120/196] | Loss: 0.3433\n",
            "Epoch: [29/50] | Step: [150/196] | Loss: 0.3863\n",
            "Epoch: [29/50] | Step: [180/196] | Loss: 0.5693\n",
            "Validating...\n",
            "Current Accuracy: 98.736%\n",
            "Best Accuracy: 98.736%\n",
            "\n",
            "Epoch: [30/50] | Step: [30/196] | Loss: 0.2866\n",
            "Epoch: [30/50] | Step: [60/196] | Loss: 0.2523\n",
            "Epoch: [30/50] | Step: [90/196] | Loss: 0.2912\n",
            "Epoch: [30/50] | Step: [120/196] | Loss: 0.2382\n",
            "Epoch: [30/50] | Step: [150/196] | Loss: 0.3297\n",
            "Epoch: [30/50] | Step: [180/196] | Loss: 0.2944\n",
            "Validating...\n",
            "Current Accuracy: 98.370%\n",
            "Best Accuracy: 98.736%\n",
            "\n",
            "Epoch: [31/50] | Step: [30/196] | Loss: 0.3145\n",
            "Epoch: [31/50] | Step: [60/196] | Loss: 0.2838\n",
            "Epoch: [31/50] | Step: [90/196] | Loss: 0.3888\n",
            "Epoch: [31/50] | Step: [120/196] | Loss: 0.4167\n",
            "Epoch: [31/50] | Step: [150/196] | Loss: 0.3992\n",
            "Epoch: [31/50] | Step: [180/196] | Loss: 0.5006\n",
            "Validating...\n",
            "Current Accuracy: 97.728%\n",
            "Best Accuracy: 98.736%\n",
            "\n",
            "Epoch: [32/50] | Step: [30/196] | Loss: 0.2718\n",
            "Epoch: [32/50] | Step: [60/196] | Loss: 0.3479\n",
            "Epoch: [32/50] | Step: [90/196] | Loss: 0.2165\n",
            "Epoch: [32/50] | Step: [120/196] | Loss: 0.3860\n",
            "Epoch: [32/50] | Step: [150/196] | Loss: 0.3794\n",
            "Epoch: [32/50] | Step: [180/196] | Loss: 0.3961\n",
            "Validating...\n",
            "Current Accuracy: 96.686%\n",
            "Best Accuracy: 98.736%\n",
            "\n",
            "Epoch: [33/50] | Step: [30/196] | Loss: 0.3014\n",
            "Epoch: [33/50] | Step: [60/196] | Loss: 0.4095\n",
            "Epoch: [33/50] | Step: [90/196] | Loss: 0.3217\n",
            "Epoch: [33/50] | Step: [120/196] | Loss: 0.3404\n",
            "Epoch: [33/50] | Step: [150/196] | Loss: 0.4008\n",
            "Epoch: [33/50] | Step: [180/196] | Loss: 0.3598\n",
            "Validating...\n",
            "Current Accuracy: 98.104%\n",
            "Best Accuracy: 98.736%\n",
            "\n",
            "Epoch: [34/50] | Step: [30/196] | Loss: 0.3994\n",
            "Epoch: [34/50] | Step: [60/196] | Loss: 0.3828\n",
            "Epoch: [34/50] | Step: [90/196] | Loss: 0.3277\n",
            "Epoch: [34/50] | Step: [120/196] | Loss: 0.3358\n",
            "Epoch: [34/50] | Step: [150/196] | Loss: 0.3469\n",
            "Epoch: [34/50] | Step: [180/196] | Loss: 0.3441\n",
            "Validating...\n",
            "Current Accuracy: 98.130%\n",
            "Best Accuracy: 98.736%\n",
            "\n",
            "Epoch: [35/50] | Step: [30/196] | Loss: 0.2368\n",
            "Epoch: [35/50] | Step: [60/196] | Loss: 0.1996\n",
            "Epoch: [35/50] | Step: [90/196] | Loss: 0.3202\n",
            "Epoch: [35/50] | Step: [120/196] | Loss: 0.2755\n",
            "Epoch: [35/50] | Step: [150/196] | Loss: 0.4875\n",
            "Epoch: [35/50] | Step: [180/196] | Loss: 0.3083\n",
            "Validating...\n",
            "Current Accuracy: 98.760%\n",
            "Best Accuracy: 98.760%\n",
            "\n",
            "Epoch: [36/50] | Step: [30/196] | Loss: 0.2013\n",
            "Epoch: [36/50] | Step: [60/196] | Loss: 0.2204\n",
            "Epoch: [36/50] | Step: [90/196] | Loss: 0.2014\n",
            "Epoch: [36/50] | Step: [120/196] | Loss: 0.2103\n",
            "Epoch: [36/50] | Step: [150/196] | Loss: 0.1690\n",
            "Epoch: [36/50] | Step: [180/196] | Loss: 0.2458\n",
            "Validating...\n",
            "Current Accuracy: 98.854%\n",
            "Best Accuracy: 98.854%\n",
            "\n",
            "Epoch: [37/50] | Step: [30/196] | Loss: 0.2538\n",
            "Epoch: [37/50] | Step: [60/196] | Loss: 0.2437\n",
            "Epoch: [37/50] | Step: [90/196] | Loss: 0.1824\n",
            "Epoch: [37/50] | Step: [120/196] | Loss: 0.2851\n",
            "Epoch: [37/50] | Step: [150/196] | Loss: 0.2233\n",
            "Epoch: [37/50] | Step: [180/196] | Loss: 0.3122\n",
            "Validating...\n",
            "Current Accuracy: 98.262%\n",
            "Best Accuracy: 98.854%\n",
            "\n",
            "Epoch: [38/50] | Step: [30/196] | Loss: 0.2214\n",
            "Epoch: [38/50] | Step: [60/196] | Loss: 0.1851\n",
            "Epoch: [38/50] | Step: [90/196] | Loss: 0.3026\n",
            "Epoch: [38/50] | Step: [120/196] | Loss: 0.4652\n",
            "Epoch: [38/50] | Step: [150/196] | Loss: 0.2781\n",
            "Epoch: [38/50] | Step: [180/196] | Loss: 0.5111\n",
            "Validating...\n",
            "Current Accuracy: 97.894%\n",
            "Best Accuracy: 98.854%\n",
            "\n",
            "Epoch: [39/50] | Step: [30/196] | Loss: 0.2291\n",
            "Epoch: [39/50] | Step: [60/196] | Loss: 0.2964\n",
            "Epoch: [39/50] | Step: [90/196] | Loss: 0.2889\n",
            "Epoch: [39/50] | Step: [120/196] | Loss: 0.2977\n",
            "Epoch: [39/50] | Step: [150/196] | Loss: 0.3050\n",
            "Epoch: [39/50] | Step: [180/196] | Loss: 0.2907\n",
            "Validating...\n",
            "Current Accuracy: 97.520%\n",
            "Best Accuracy: 98.854%\n",
            "\n",
            "Epoch: [40/50] | Step: [30/196] | Loss: 0.3695\n",
            "Epoch: [40/50] | Step: [60/196] | Loss: 0.3035\n",
            "Epoch: [40/50] | Step: [90/196] | Loss: 0.3216\n",
            "Epoch: [40/50] | Step: [120/196] | Loss: 0.2928\n",
            "Epoch: [40/50] | Step: [150/196] | Loss: 0.4866\n",
            "Epoch: [40/50] | Step: [180/196] | Loss: 0.2781\n",
            "Validating...\n",
            "Current Accuracy: 98.068%\n",
            "Best Accuracy: 98.854%\n",
            "\n",
            "Epoch: [41/50] | Step: [30/196] | Loss: 0.2201\n",
            "Epoch: [41/50] | Step: [60/196] | Loss: 0.2254\n",
            "Epoch: [41/50] | Step: [90/196] | Loss: 0.2649\n",
            "Epoch: [41/50] | Step: [120/196] | Loss: 0.2217\n",
            "Epoch: [41/50] | Step: [150/196] | Loss: 0.2641\n",
            "Epoch: [41/50] | Step: [180/196] | Loss: 0.3018\n",
            "Validating...\n",
            "Current Accuracy: 98.648%\n",
            "Best Accuracy: 98.854%\n",
            "\n",
            "Epoch: [42/50] | Step: [30/196] | Loss: 0.2738\n",
            "Epoch: [42/50] | Step: [60/196] | Loss: 0.1882\n",
            "Epoch: [42/50] | Step: [90/196] | Loss: 0.1494\n",
            "Epoch: [42/50] | Step: [120/196] | Loss: 0.1469\n",
            "Epoch: [42/50] | Step: [150/196] | Loss: 0.1375\n",
            "Epoch: [42/50] | Step: [180/196] | Loss: 0.1484\n",
            "Validating...\n",
            "Current Accuracy: 99.520%\n",
            "Best Accuracy: 99.520%\n",
            "\n",
            "Epoch: [43/50] | Step: [30/196] | Loss: 0.1628\n",
            "Epoch: [43/50] | Step: [60/196] | Loss: 0.2598\n",
            "Epoch: [43/50] | Step: [90/196] | Loss: 0.1576\n",
            "Epoch: [43/50] | Step: [120/196] | Loss: 0.1415\n",
            "Epoch: [43/50] | Step: [150/196] | Loss: 0.1449\n",
            "Epoch: [43/50] | Step: [180/196] | Loss: 0.1347\n",
            "Validating...\n",
            "Current Accuracy: 99.548%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Epoch: [44/50] | Step: [30/196] | Loss: 0.0936\n",
            "Epoch: [44/50] | Step: [60/196] | Loss: 0.1895\n",
            "Epoch: [44/50] | Step: [90/196] | Loss: 0.1695\n",
            "Epoch: [44/50] | Step: [120/196] | Loss: 0.1635\n",
            "Epoch: [44/50] | Step: [150/196] | Loss: 0.1469\n",
            "Epoch: [44/50] | Step: [180/196] | Loss: 0.1406\n",
            "Validating...\n",
            "Current Accuracy: 99.538%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Epoch: [45/50] | Step: [30/196] | Loss: 0.1208\n",
            "Epoch: [45/50] | Step: [60/196] | Loss: 0.1142\n",
            "Epoch: [45/50] | Step: [90/196] | Loss: 0.1325\n",
            "Epoch: [45/50] | Step: [120/196] | Loss: 0.0801\n",
            "Epoch: [45/50] | Step: [150/196] | Loss: 0.1572\n",
            "Epoch: [45/50] | Step: [180/196] | Loss: 0.1755\n",
            "Validating...\n",
            "Current Accuracy: 99.444%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Epoch: [46/50] | Step: [30/196] | Loss: 0.1422\n",
            "Epoch: [46/50] | Step: [60/196] | Loss: 0.1356\n",
            "Epoch: [46/50] | Step: [90/196] | Loss: 0.1241\n",
            "Epoch: [46/50] | Step: [120/196] | Loss: 0.1373\n",
            "Epoch: [46/50] | Step: [150/196] | Loss: 0.2260\n",
            "Epoch: [46/50] | Step: [180/196] | Loss: 0.3149\n",
            "Validating...\n",
            "Current Accuracy: 98.114%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Epoch: [47/50] | Step: [30/196] | Loss: 0.2832\n",
            "Epoch: [47/50] | Step: [60/196] | Loss: 0.2768\n",
            "Epoch: [47/50] | Step: [90/196] | Loss: 0.3599\n",
            "Epoch: [47/50] | Step: [120/196] | Loss: 0.2957\n",
            "Epoch: [47/50] | Step: [150/196] | Loss: 0.3677\n",
            "Epoch: [47/50] | Step: [180/196] | Loss: 0.3865\n",
            "Validating...\n",
            "Current Accuracy: 95.984%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Epoch: [48/50] | Step: [30/196] | Loss: 0.5683\n",
            "Epoch: [48/50] | Step: [60/196] | Loss: 0.4459\n",
            "Epoch: [48/50] | Step: [90/196] | Loss: 0.4823\n",
            "Epoch: [48/50] | Step: [120/196] | Loss: 0.2981\n",
            "Epoch: [48/50] | Step: [150/196] | Loss: 0.4459\n",
            "Epoch: [48/50] | Step: [180/196] | Loss: 0.3860\n",
            "Validating...\n",
            "Current Accuracy: 96.122%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Epoch: [49/50] | Step: [30/196] | Loss: 0.3502\n",
            "Epoch: [49/50] | Step: [60/196] | Loss: 0.2221\n",
            "Epoch: [49/50] | Step: [90/196] | Loss: 0.2747\n",
            "Epoch: [49/50] | Step: [120/196] | Loss: 0.3144\n",
            "Epoch: [49/50] | Step: [150/196] | Loss: 0.2887\n",
            "Epoch: [49/50] | Step: [180/196] | Loss: 0.1678\n",
            "Validating...\n",
            "Current Accuracy: 98.582%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Epoch: [50/50] | Step: [30/196] | Loss: 0.1263\n",
            "Epoch: [50/50] | Step: [60/196] | Loss: 0.1302\n",
            "Epoch: [50/50] | Step: [90/196] | Loss: 0.1439\n",
            "Epoch: [50/50] | Step: [120/196] | Loss: 0.1158\n",
            "Epoch: [50/50] | Step: [150/196] | Loss: 0.1607\n",
            "Epoch: [50/50] | Step: [180/196] | Loss: 0.2219\n",
            "Validating...\n",
            "Current Accuracy: 99.278%\n",
            "Best Accuracy: 99.548%\n",
            "\n",
            "Train Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HvFIDZN82KDC"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    print(\"Evaluating Test Dataset...\")\n",
        "    print()\n",
        "    best_accuracy = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        count = 0\n",
        "\n",
        "        for (images, labels) in test_loader:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Handle tuple outputs (e.g., for GoogleNet with auxiliary classifiers)\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]  # Only take the primary output\n",
        "\n",
        "            # top-1 accuracy\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.shape[0]\n",
        "            correct += torch.eq(predicted, labels).sum().item()\n",
        "\n",
        "            # top-5 accuracy\n",
        "            _, predicted = torch.topk(outputs, 5)\n",
        "            for gt, pred in zip(labels, predicted):\n",
        "                if gt in pred:\n",
        "                    count += 1\n",
        "\n",
        "        top1_acc = (correct / total) * 100\n",
        "        top5_acc = (count / total) * 100\n",
        "        print(f\"Test Top-1 Accuracy: {top1_acc:.2f}%\")\n",
        "        print(f\"Test Top-5 Accuracy: {top5_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogleNet(in_channels=3, num_classes=100).cuda()\n",
        "model.load_state_dict(torch.load(\"./model_without_cbam.pt\"))\n",
        "test(model=model, test_loader=test_loader, criterion=criterion1) # No CBAM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMEcJvzY3Z68",
        "outputId": "971e67fe-2341-48f8-c7c3-977a19bfd841"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-602af871309b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"./model_without_cbam.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Test Dataset...\n",
            "\n",
            "Test Top-1 Accuracy: 28.07%\n",
            "Test Top-5 Accuracy: 54.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogleNet_CBAM(in_channels=3, num_classes=100).cuda()\n",
        "model.load_state_dict(torch.load(\"./model_cbam.pt\"))\n",
        "test(model=model, test_loader=test_loader, criterion=criterion2) # With CBAM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pki1V3Cj3Zu_",
        "outputId": "71ecbabf-2bbf-4dff-a32f-293c23b4a0d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Test Dataset...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-58e10ff0456e>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"./model_cbam.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Top-1 Accuracy: 28.92%\n",
            "Test Top-5 Accuracy: 55.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pRLTUzdg4btS"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}